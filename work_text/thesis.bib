% !TeX encoding = windows-1251

@BOOK{teorver,
  author      = {Николаевич, Ш.А.},
  title       = {Вероятность-1},
  isbn        = {9785443915579},
  publisher   = {МЦНМО},
  address     = {Москва},
  year        = {2021},
  language     = {russian},
}

@BOOK{python-book,
  author      = {Васильев, А.Н.},
  title       = {Программирование на PYTHON в примерах и задачах},
  isbn        = {9785041031992},
  publisher   = {Эксмо},
  address     = {Москва},
  year        = {2021},
  language     = {russian},
}

@BOOK{simplex,
  author      = {Таха, Х.А.},
  title       = {Введение в исследование операций},
  isbn        = {9785845907400},
  publisher   = {Вильямс},
  address     = {Москва},
  year        = {2007},
  language     = {russian},
}

@BOOK{deeplearn,
  author      = {Николенко, С.И.},
  title       = {Глубокое обучение погружение в мир нейронных сетей},
  isbn        = {9785496025362},
  publisher   = {Питер},
  address     = {Санкт-Петербург},
  year        = {2018},
  language     = {russian},
}

@ARTICLE{reg,
  author       = {К. В. Воронцов and А. А. Потапенко},
  title        = {Регуляризация вероятностных тематических моделей для повышения интерпретируемости и определения числа тем},
  journal      = {Компьютерная лингвистика и интеллектуальные технологии},
  year         = {2014},
  volume       = {13},
  number       = {20},
  pages        = {268--271},
  language     = {russian},
}

@ARTICLE{ARTM,
  author       = {К. В. Воронцов},
  title        = {Аддитивная регуляризация тематических моделей коллекций текстовых документов},
  journal      = {Доклады академии наук},
  year         = {2014},
  volume       = {456},
  number       = {3},
  pages        = {676--687},
  language     = {russian},
}

@BOOK{all,
title={Вероятностное тематическое моделирование: теория регуляризации ARTM и
библиотека с открытым исходным кодом BigARTM [{Э}лектронный ресурс]},
note={URL:~\url{http://www.machinelearning.ru/wiki/images/d/d5/Voron17survey-artm.pdf} (Дата обращения 26.10.2024). Загл. с экр. Яз. рус.},
}

@BOOK{bigartm-book,
title={BigARTM. Примеры обучения моделей на Python [{Э}лектронный ресурс]},
note={URL:~\url{https://github.com/bigartm/bigartm-book/blob/master/ARTM_tutorial_Fun.ipynb} (Дата обращения 01.02.2025). Загл. с экр. Яз. рус.},
}

@BOOK{bigartm,
title={BigARTM's documentation [{Э}лектронный ресурс]},
note={URL:~\url{https://docs.bigartm.org/en/stable/index.html} (Дата обращения 01.02.2025). Загл. с экр. Яз. англ.},
}

@BOOK{predobr,
title={Тематическое моделирование средствами BigARTM. [{Э}лектронный ресурс]},
note={URL:~\url{https://habr.com/ru/articles/334668/} (Дата обращения 01.10.2024). Загл. с экр. Яз. рус.},
}

@BOOK{pandas,
title={User Guide [{Э}лектронный ресурс]},
note={URL:~\url{https://pandas.pydata.org/docs/user_guide/index.html} (Дата обращения 05.02.2025). Загл. с экр. Яз. англ.},
}

@BOOK{numpy,
title={NumPy user guide [{Э}лектронный ресурс]},
note={URL:~\url{https://numpy.org/doc/stable/user/index.html} (Дата обращения 01.03.2025). Загл. с экр. Яз. англ.},
}

@BOOK{nltk,
title={NLTK [{Э}лектронный ресурс]},
note={URL:~\url{https://www.nltk.org/} (Дата обращения 01.04.2025). Загл. с экр. Яз. англ.},
}

@BOOK{pymorphy2,
title={Морфологический анализатор pymorphy2 [{Э}лектронный ресурс]},
note={URL:~\url{https://pymorphy2.readthedocs.io/en/stable/} (Дата обращения 01.04.2025). Загл. с экр. Яз. рус.},
}

@BOOK{scr,
title={Техники и методы для извлечения информации [{Э}лектронный ресурс]},
note={URL:~\url{https://www.contact-center.ru/faq/kak-parsit-dannye-tekhniki-i-metody-dlya-izvlecheniya-informatsii/} (Дата обращения 01.04.2024). Загл. с экр. Яз. рус.},
}


@BOOK{all-neu,
title={Классификация данных с помощью нейронных сетей [{Э}лектронный ресурс]},
note={URL:~\url{https://loginom.ru/blog/neural-classification} (Дата обращения 01.04.2025). Загл. с экр. Яз. рус.},
}


@BOOK{attention,
title={Attention is all you need [{Э}лектронный ресурс]},
note={URL:~\url{https://habr.com/ru/articles/781770/} (Дата обращения 01.04.2025). Загл. с экр. Яз. рус.},
}