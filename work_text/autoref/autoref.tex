\documentclass[autoref]{SCWorks}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{array}
\usepackage[english,russian]{babel}
\usepackage{minted}
% Используется автором репозитория
\usemintedstyle{xcode}
\usepackage[colorlinks=false]{hyperref}

\usepackage[autostyle]{csquotes}

\usepackage{tempora}
\usepackage{cmap}
% ==============================================================================
\newcommand{\eqdef}{\stackrel {\rm def}{=}}
\newtheorem{lem}{Лемма}
\hypersetup{
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black
}
\AtBeginEnvironment{minted}{\renewcommand{\fcolorbox}[4][]{#4}}

\newcommand{\mintcode}[2]{
    \usemintedstyle{vs}
    \inputminted[fontsize=#1, encoding=utf8, outencoding=utf8]{python}{#2}
}
% ==============================================================================
\begin{document}

% Кафедра (в родительном падеже)
\chair{математической кибернетики и компьютерных наук}

% Тема работы
\title{Автоматическая тематическая классификация новостного массива}

% Курс
\course{4}

% Группа
\group{451}

% Факультет (в родительном падеже) (по умолчанию "факультета КНиИТ")
% \department{факультета КНиИТ}

% Специальность/направление код - наименование
\napravlenie{09.03.04 "--- Программная инженерия}

% Фамилия, имя, отчество в родительном падеже
\author{Кондрашова Даниила Владиславовича}

% Заведующий кафедрой 
\chtitle{доцент, к.\,ф.-м.\,н.}
\chname{С.\,В.\,Миронов}

% Научный руководитель
\satitle{доцент, к.\,ф.-м.\,н.} % должность, степень, звание
\saname{С.\,В.\,Папшев}

% Руководитель практики от организации (руководитель для цифровой кафедры)
\patitle{доцент, к.\,ф.-м.\,н.}
\paname{С.\,В.\,Миронов}

% Год выполнения отчета
\date{2025}
% ==============================================================================
\maketitle
% Включение нумерации рисунков, формул и таблиц по разделам (по умолчанию -
% нумерация сквозная) (допускается оба вида нумерации)
\secNumbering
% ==============================================================================
% Введение
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\intro
В настоящее время оперативный поиск информации становится критически важной
задачей. Однако анализ полного массива данных невозможен из"=за его масштабов,
что создаёт необходимость в классификации и последующей фильтрации данных для
выделения релевантной информации. Решением этой проблемы может служить
тематическая классификация.

Большие объёмы данных, такие как новостные потоки, часто не имеют системной
тематической разметки. Даже при наличии рубрикации, её субъективность может
приводить к проблемам: некорректному присвоению тем, избыточности тематических
категорий и их недостаточному охвату. Это вызывает ошибки при поиске и анализе
информации. Для устранения этих недостатков требуется механизм, обеспечивающий
точную тематическую классификацию с возможностью автоматической разметки
новостных материалов.

Одним из инструментов для реализации такого подхода являются тематические
модели в сочетании с алгоритмами глубокого обучения. Первые позволяют выявить
скрытые темы в текстовых данных и подготовить разметку для обучения вторых.
Алгоритмы глубокого обучения, в свою очередь, могут классифицировать новые
тексты по заданным темам.

Таким образом, целью данной работы является разработка нейросетевого метода
автоматической классификации новостей на основе тематической модели предметной
области.

Для достижения цели необходимо решить следующие задачи:
\begin{enumerate}
    \item Выполнить парсинг новостных данных и их текстовую предобработку;
    \item Провести анализ характеристик и параметров набора данных;
    \item Выполнить тематическое моделирование подготовленных данных с
    оптимальными параметрами;
    \item Разметить данные для обучения нейронной сети"=классификатора с
    помощью тематического моделирования;
    \item Выполнить обучение нейронной сети"=классификатора на размеченных
    данных;
    \item Провести анализ качетсва обученной модели;
    \item Проанализировать эффективность разработанного метода автоматической
    тематической классификации.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Структура и объём работы.}
Для решения поставленных задач выполнена выпускная квалификационная работа,
включающая в себя введение, 2 основные главы, заключение, список использованных
источников из 29 наименований и 11 приложений. Работа изложена на 97
страницах.

Первая глава имеет название \enquote{Теоретические и методологические основы
автоматической тематической классификации} и содержит информацию об основных
подходах и инструментах используемых в автоматической тематической
классификации.

Вторая глава имеет название \enquote{Практико"=технологические основы
автоматической тематической классификации} и содержит подробное
описание процесса выполнения работы и кракткие итоги по каждому из
реализованных пунктов.

Завершается выпускная квалификационная работа заключением, списком
использованных источников, а также приложениями с кодом А"=Л.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Теоретические и методологические основы автоматической тематической
классификации}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Сбор новостных данных.}
Подраздел \enquote{Сбор новостных данных} посвящён методологии формирования
новостного корпуса. Проведён сравнительный анализ трёх принципиальных подходов
к получению данных: ручного сбора, запросов через API и автоматизированного
веб"=скрапинга. Ручной метод отвергнут из"=за низкой производительности, а
API"=интеграция "--- ввиду ограниченной применимости (неоперативность
предоставления данных владельцами платформ). В результате обоснован выбор
веб"=скрапинга как оптимального метода, сочетающего высокую скорость обработки
с минимальной зависимостью от внешних факторов.

Детально рассмотрены критерии отбора новостной платформы. Ключевыми требованиями
выступили: единая структура HTML"=документов на всём сайте, отсутствие
системных блокировок HTTP"=запросов и статичность контента (полная доступность
информации без динамической подгрузки через JavaScript). На основе этих
критериев выбран сайт НИУ ВШЭ, полностью соответствующий установленным
требованиям. Особо отмечена его структурная однородность новостных материалов,
что исключает необходимость ручной настройки парсера под разноформатные
документы.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Подготовка собранных данных.}
Подраздел \enquote{Подготовка собранных данных} детализирует методологию
предобработки новостного корпуса, где ключевой задачей выступает устранение шума
при сохранении семантической целостности текстов. Основой обработки стала
лингвистическая нормализация, требующая выбора метода приведения слов к
словарной форме. После сравнительного анализа стемминга и лемматизации
предпочтение отдано лемматизации как методике, гарантирующей корректное
сохранение семантики терминов. Это критически важно для последующего
тематического моделирования, где искажение смысла слов приводит к ошибочной
интерпретации контекста.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Математические основы тематического моделирования.}
Подраздел \enquote{Математические основы тематического моделирования}
обосновывает применение тематического моделирования как ключевого инструмента
для решения задачи автоматической разметки новостных данных. Центральная
гипотеза метода заключается в том, что тексты формируются из скрытых
тематических распределений, а слова порождаются конкретными темами, а не
документами. Это позволяет выявлять латентные семантические структуры в больших
текстовых коллекциях без ручной аннотации.

Основная практическая цель использования тематического моделирования в работе
"--- подготовка размеченных данных для обучения нейросетевого классификатора.
Традиционная ручная разметка неприменима из"=за масштабов новостных потоков и
субъективности человеческой оценки. Тематические модели решают эту проблему,
автоматически присваивая документам вероятностные распределения по темам на
основе частотных закономерностей терминов.

Критически важным аспектом является обеспечение интерпретируемости и
устойчивости моделей. Для этого применена аддитивная регуляризация (ARTM),
позволяющая контролировать свойства матриц распределений слов и тем.
Регуляризаторы решают проблемы избыточного перекрытия тематик и повышают
семантическую согласованность терминов внутри тем.

Раздел также включает анализ метрик оценки качества моделей. Рассмотрены
внутренние критерии: перплексия (степень предсказуемости текста), когерентность
тем (семантическая связность топовых слов) и разреженность распределений. Эти
показатели позволяют объективно сравнивать эффективность различных конфигураций
модели без привлечения экспертов.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Методы обработки текста с помощью нейросетей.}
Подраздел \enquote{Методы обработки текста с помощью нейросетей} посвящён
обоснованию выбора нейросетевой архитектуры для тематической классификации.
Проведён критический анализ методов преобразования текста в векторные
представления. Рассмотрены классические подходы (Bag"=of"=Words, TF"=IDF),
отвергнутые из"=за принципиальных ограничений: высокая размерность,
игнорирование контекста и семантических связей. Обоснован приоритет
семантических эмбеддингов "--- плотных векторных представлений слов, сохраняющих
смысловую близость терминов и адаптируемых к новым лексическим единицам.

Детально исследованы архитектуры нейронных сетей для обработки
последовательностей. Выявлены недостатки рекуррентных моделей (RNN/LSTM):
низкая скорость из"=за последовательных вычислений, проблемы с длинными
зависимостями и затухание градиентов. В качестве решения предложены
трансформеры, чей механизм self"=attention обеспечивает:

\begin{enumerate}
    \item параллельную обработку токенов;
    \item учёт глобального контекста через анализ взаимовлияния слов;
    \item эффективную работу с протяжёнными текстами.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Вывод по первому разделу:} проведён комплексный анализ инструментальных
средств и методологий для реализации автоматической тематической классификации
новостных массивов. На системном уровне рассмотрены альтернативные подходы к
сбору данных, предобработке текстов, тематическому моделированию и нейросетевой
классификации, после чего обоснован выбор оптимальных решений для каждого этапа.
Для ключевых компонентов системы (веб"=скрапинг, лингвистическая нормализация,
регуляризация тематических моделей, трансформерные архитектуры) детализированы
критерии выбора, подтверждающие эффективность отобранных инструментов.
Дополнительно исследованы математические принципы работы тематического
моделирования как фундаментального элемента системы, с акцентом на механизмы
регуляризации и оценки качества моделей. Сформированная методологическая база
обеспечивает теоретическую основу для практической реализации алгоритма.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Практико"=технологические основы автоматической тематической
классификации}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Получение новостного массива путём веб"=скраппинга.}
Подраздел \enquote{Получение новостного массива путём веб"=скраппинга} посвящён
разработке программного компонента для сбора новостного массива, а также
рассмотрению количественных характеристик собранных данных.

Реализация сбора данных выполнена на языке Python с использованием
специализированных библиотек. Для отправки HTTP"=запросов применена библиотека
Requests, обеспечивающая эффективное получение HTML"=кода страниц. Парсинг
извлечённого контента осуществлён средствами BeautifulSoup4, позволяющей
анализировать структуру документов через поиск по тегам и CSS"=классам. Отказ от
Selenium обоснован статичностью сайта"=источника (НИУ ВШЭ), не требующей
эмуляции браузерного взаимодействия.

Разработан алгоритм, включающий: анализ структуры новостных карточек, извлечение
метаданных (заголовков, дат, анонсов), рекурсивное получение полных текстов по
внутренним ссылкам. Оптимизация производительности достигнута за счёт реализации
многопоточности через стандартные средства Python, что ускорило обработку
архивных страниц. Результатом работы алгоритма стал структурированный набор
данных в формате Excel, содержащий 17 430 документов с полными текстами и
атрибутами. Количественные характеристики корпуса подтверждают
репрезентативность выборки: общий объём превышает 12 миллионов токенов при
средней длине документа 695 слов.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Подготовка новостного массива.}
Подраздел \enquote{Подготовка новостного массива} посвящен разработке программного
компонента для предобработки новостного массива, а также рассмотрению
экспериментальных результатов подготовки данных. 

Реализация предобработки данных выполнена на Python с использованием библиотеки
SpaCy для лингвистической нормализации. Выбор SpaCy обоснован её способностью к
контекстному анализу, интегрированному конвейеру токенизации и лемматизации, а
также высокой точности предобученных моделей для русского и английского языков.
Однако выявлено ограничение: встроенные словари стоп"=слов недостаточно
эффективны для специализированных новостных корпусов, где частотные термины
могут быть тематически значимыми (например, \enquote{котировка} в финансовых
текстах).

Для решения этой проблемы разработан и реализован гибридный подход. Он дополняет
стандартную фильтрацию SpaCy метрикой TF"=IDF, рассчитываемой средствами
библиотеки Gensim. Данная метрика автоматически идентифицирует и удаляет
низкозначимые термины на основе их распределения в корпусе, обеспечивая
адаптивность к тематической специфике. Дополнительно реализованы: алгоритмы
очистки от нетекстовых элементов с пороговым контролем (50\% неалфавитных
символов), обработка мультиязычных фрагментов через разделение
русско"=английских сегментов, удаление документов с недостаточным содержанием
(<80 токенов).

Результатом обработки стал очищенный корпус из 11 860 документов. Ключевой
эффект "--- сокращение словаря на 93\% (с 278 724 до 18 707 уникальных токенов)
при сохранении семантической целостности текстов.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Построение тематической модели.}
Подраздел \enquote{Построение тематической модели} посвящен разработке
программных компонентов для осуществления тематического моделирования, а также
рассмотрению экспериментальных результатов проведённого тематического
моделирования. 

Библиотека BigARTM выбрана как основной инструмент тематического
моделирования благодаря её поддержке аддитивной регуляризации (ARTM),
позволяющей гибко контролировать свойства тем через комбинацию сглаживающих,
декоррелирующих и разреживающих регуляризаторов. Для расширения функциональности
разработаны два специализированных класса:\\My\_BigARTM\_model (добавляет расчёт
когерентности, визуализацию динамики метрик и упрощённый интерфейс
регуляризации) и Hyperparameter\_optimizer (реализует интеллектуальный подбор
параметров через Optuna).

Эксперименты на 11 конфигурациях данных дали следующие результаты. С
одной стороны, достигнуты высокие значения метрик: когерентность до 0.537
(TF"=IDF порог 10\%), перплексия до 2810 (TF"=IDF 1\% + декорреляция). С другой,
все модели показали критически высокое перекрытие тематических распределений,
что подтверждается визуальным анализом и отклонением от эталонной разметки на
84\%. Гипотезы причин включают недостаточный объём данных и ограниченность
гиперпараметрического поиска.

Практическим итогом этапа стало создание автоматизированного конвейера
тематической разметки на основе матрицы $\theta$. Полученный датасет с
вероятностными распределениями тем по документам использован для обучения
нейросетевого классификатора, хотя его низкое качество (F1 < 0.25) указывает на
фундаментальные ограничения подхода для выбранного корпуса.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Обучение модели классификатора.}
Подраздел \enquote{Обучение модели классификатора} посвящен разработке
программных компонентов для осуществления обучения нейросетевого классификатора,
а также рассмотрению экспериментальных результатов обучения и проведению их
анализа.

Реализация этапа основана на предобученной модели RoBERTa, выбранной за её
эффективность в анализе контекстных зависимостей. Интеграция выполнена через
платформу Hugging Face, обеспечившую доступ к инструментарию обучения. Для
обработки текстов применён специализированный токенизатор.

Разработан класс TopicClassifier, автоматизирующий конвейер обработки:
преобразование меток, токенизацию данных, настройку параметров обучения
(скорость обучения 2e"=5, размер батча 32) и мониторинг метрик качества.

Эксперименты на 12 конфигурациях данных показали точность ниже ожидаемой:
accuracy в диапазоне 0.166"=0.291, F1"=мера "--- 0.035"=0.252. Наилучший
результат достигнут без TF"=IDF обработки. Контрольный тест с ручной разметкой
ВШЭ подтвердил потенциал архитектуры, продемонстрировав accuracy 0.71. Это
указывает, что тематическая разметка требует уточнения, а не замены
классификатора. Дополнительные оптимизации (сокращение словаря, биграммы) не
дали значимого улучшения.

Перспективным направлением признано совершенствование тематического
моделирования: увеличение объёма данных, расширение перебора гиперпараметров и
раннее применение регуляризации способны повысить точность разметки и, как
следствие, качество классификации.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Вывод по второму разделу:} разработан комплекс программных компонентов,
реализующих полный цикл автоматической тематической классификации "--- от сбора
данных до нейросетевого предсказания. Практическая реализация включает: создание
парсера на Python с использованием библиотек Requests и BeautifulSoup4,
разработку гибридного подхода к предобработке текста (SpaCy + TF"=IDF
фильтрация), построение расширенного решения для тематического моделирования на
базе BigARTM с классами"=обёртками, а также внедрение классификатора RoBERTa
через Hugging Face API.

Экспериментальные результаты подтвердили работоспособность системы: успешно
собран корпус из 17 430 документов, сокращение словаря на 93\% при сохранении
семантической целостности, автоматическая тематическая разметка данных. При этом
выявлены направления для улучшения: точность классификации (0.166"=0.291
accuracy) оказалась ниже ожидаемой, что связано главным образом с неточностью
тематической разметки. Контрольный эксперимент с ручной разметкой (accuracy
0.71) подтвердил адекватность архитектуры классификатора и обозначил перспективу
улучшения через совершенствование тематического моделирования.

Ключевой практический итог "--- создание модульной системы, готовой к интеграции
и дальнейшей оптимизации путём увеличения объёма данных, расширенного подбора
гиперпараметров и модификации регуляризационных стратегий.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\conclusion
В ходе данной дипломной работы был разработан алгоритм автоматической
классификации новостей на основе тематической модели предметной области.

Для этого было выполнено следующее:

\begin{enumerate}
    \item Проведён анализ инструментов по сбору данных и выбраны
    наиболее удобные из них (BeautifulSoup4, requests);
    \item Проведён сбор данных;
    \item Проанализированы способы обработки текстовых данных
    и выбраны наиболее удобные из них;
    \item Проанализированы популярные инструменты для обработки
    текстовых данных (NLTK, Pymorphy3, SpaCy) и выбран наиболее
    удобный и точный из них (SpaCy);
    \item Проведена подготовка данных для тематического моделирования и
    проведён анализ её результатов;
    \item Изучен механизм тематического моделирования с помошью
    аддитивной тематической регуляризации;
    \item Разработаны инструменты для тематической классификации с
    помощью библиотеки BigARTM;
    \item Проведены эксперименты по проведению тематической классификации
    над подготовленными различными способами данными, а также
    проведён анализ результатов экспериментов;
    \item Рассмотрены различные способы обработки текстовых данных нейронными
    сетями и выбран наиболее подходящий из них (семантическое векторное
    представление);
    \item Проведён анализ архитектур подходящих типов нейронных сетей
    и выбрана наиболее подходящая из них (transformer);
    \item Проведён анализ доступных предобученных сетей и сервисов, которые
    их предоставляют, в ходе которого выбран наиболее удобный из них (Hugging
    Face и Roberta);
    \item Проведены эксперименты по обучению тематического классификатора
    новостей, а также выполнен анализ результатов и сделаны соответствующие
    выводы.
\end{enumerate}

Основной вывод по итогам работы: предложенный метод автоматической классификации
имеет перспективу применения при более тщательном тематическом моделировании
исходного набора данных.

\end{document}